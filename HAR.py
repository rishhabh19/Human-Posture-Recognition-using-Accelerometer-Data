# -*- coding: utf-8 -*-
"""project maamla.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o8bD77_lO-F7qpc3dM1F3gsLybb0_W2_
"""

import numpy as np 
import pandas as pd 
import seaborn as sns
sns.set(style="white") #white background style for seaborn plots
sns.set(style="whitegrid", color_codes=True)
from sklearn.preprocessing import StandardScaler
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn import linear_model, decomposition, datasets

from google.colab import drive
drive.mount('/content/drive')

train = pd.read_csv("/content/drive/My Drive/Copy of HAR dataset.csv", delimiter=';')
train

train['gender'] = train['gender'].apply(lambda x: 0 if x=='Woman' else 1)
train.head()
from sklearn.utils import shuffle
train = shuffle(train)

x = train.iloc[:, 6:-1]
y = train.iloc[:, -1]
y

index = x[x.z4 == '-14420-11-2011 04:50:23.713'].index
x.drop(index, inplace=True)
y.drop(index, inplace=True)

# for i in range(len(y)):
#     if(y[i] == "sitting"): 
#         y[i] = 1
#     if(y[i] == "sittingdown"): 
#         y[i] = 2
#     if(y[i] == "standing"): 
#         y[i] = 3
#     if(y[i] == "standingup"): 
#         y[i] = 4
#     if(y[i] == "walking"): 
#         y[i] = 5

from sklearn.model_selection import train_test_split
xtrain, xtest, ytrain, ytest = train_test_split(x, y)
print(xtrain.shape)
print(xtest.shape)
print(ytrain.shape)
print(ytest.shape)

from sklearn.linear_model import SGDClassifier
sgd = SGDClassifier()
sgd.fit(xtrain, ytrain )

sgd.score(xtest, ytest)

sgd.score(xtrain, ytrain)

n = len(x)
j = 0
x1 = x.to_numpy()
y1 = y.to_numpy()
for i in range(3):
    xtest = x1[j:j+n//3]
    ytest = y1[j:j+n//3]
    xtrain = np.concatenate( (x1[:j],x1[j+n//3:]))
    ytrain = np.concatenate( (y1[:j],y1[j+n//3:]))
    sgd.fit(xtrain[:1000], ytrain[:1000])
    j+=n//3
    print(sgd.score(xtest, ytest))

from sklearn.metrics import plot_confusion_matrix
plot_confusion_matrix(sgd, xtest, ytest,  normalize = 'pred')
sns.set(font_scale=0.75)
plt.show()

from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
qd = QuadraticDiscriminantAnalysis()

qd.fit(xtrain, ytrain)

qd.score(xtest, ytest)

qd.score(xtrain, ytrain)

n = len(x)
j = 0
x1 = x.to_numpy()
y1 = y.to_numpy()
for i in range(3):
    xtest = x1[j:j+n//3]
    ytest = y1[j:j+n//3]
    xtrain = np.concatenate( (x1[:j],x1[j+n//3:]))
    ytrain = np.concatenate( (y1[:j],y1[j+n//3:]))
    qd.fit(xtrain[:1000], ytrain[:1000])
    j+=n//3
    print(qd.score(xtest, ytest))

plot_confusion_matrix(qd, xtest, ytest,  normalize = 'pred')
sns.set(font_scale=0.75)
plt.show()



from sklearn.linear_model import LogisticRegression
lr = LogisticRegression(max_iter = 500)
lr.fit(xtrain, ytrain)

lr.score(xtest,ytest)

lr.score(xtrain, ytrain)

ypred = lr.predict(xtest)
ypred

from sklearn.metrics import confusion_matrix
confusion_matrix(ytest, ypred, labels = ['sitting' ,'sittingdown' ,'standing' ,'standingup' ,'walking'])

from sklearn.metrics import plot_confusion_matrix
plot_confusion_matrix(lr, xtest, ytest,  normalize = 'pred')
sns.set(font_scale=0.75)
plt.show()

plot_confusion_matrix(lr, xtest, ytest,  cmap = 'inferno')
sns.set(font_scale=0.75)
plt.show()

n = len(x)
j = 0
x1 = x.to_numpy()
y1 = y.to_numpy()
for i in range(3):
    xtest = x1[j:j+n//3]
    ytest = y1[j:j+n//3]
    xtrain = np.concatenate( (x1[:j],x1[j+n//3:]))
    ytrain = np.concatenate( (y1[:j],y1[j+n//3:]))
    lr.fit(xtrain[:1000], ytrain[:1000])
    j+=n//3
    print(lr.score(xtest, ytest))

from sklearn.svm import SVC
svm = SVC(kernel = 'rbf')
svm.fit(xtrain[:20000], ytrain[:20000])

svm.score(xtest, ytest)

svm.score(xtrain, ytrain)

plot_confusion_matrix(svm, xtest, ytest,  normalize = 'pred')
sns.set(font_scale=0.75)
plt.show()

ypred = svm.predict(xtest)
plot_confusion_matrix(svm, xtest, ytest,  cmap = 'inferno')
sns.set(font_scale=0.75)
plt.show()

n = len(x)
j = 0
x1 = x
y1 =  y
x1 = x.to_numpy()
y1 = y.to_numpy()
for i in range(3):
    xtest = x1[j:j+n//3]
    ytest = y1[j:j+n//3]
    xtrain = np.concatenate( (x1[:j],x1[j+n//3:]))
    ytrain = np.concatenate( (y1[:j],y1[j+n//3:]))
    svm.fit(xtrain[:1000], ytrain[:1000])
    print(svm.score(xtest, ytest))
    j+=n//3

from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier(max_depth = 16)

rf.fit(xtrain, ytrain)

rf.score(xtest, ytest)

rf.score(xtrain ,ytrain)

from sklearn.metrics import plot_confusion_matrix
plot_confusion_matrix(rf, xtest, ytest,  cmap = 'inferno')
sns.set(font_scale=0.75)
plt.show()

plot_confusion_matrix(rf, xtest, ytest,  normalize = 'pred')
sns.set(font_scale=0.75)
plt.show()

n = len(x)
j = 0
x1 = x
y1 =  y
x1 = x.to_numpy()
y1 = y.to_numpy()
for i in range(3):
    xtest = x1[j:j+n//3]
    ytest = y1[j:j+n//3]
    xtrain = np.concatenate( (x1[:j],x1[j+n//3:]))
    ytrain = np.concatenate( (y1[:j],y1[j+n//3:]))
    rf = RandomForestClassifier()
    rf.fit(xtrain, ytrain)
    print(rf.score(xtest, ytest))
    del(rf)
    j+=n//3



from sklearn.neural_network import MLPClassifier
nn = MLPClassifier()
nn.fit(xtrain, ytrain)

act = ['relu', 'identity','logistic','tanh']
alpha = [1, 0.1, 0.05, 0.01]
acc = []
for a in alpha:
  for ac in act:
    nn = MLPClassifier(alpha= a, activation= ac)
    nn.fit(xtrain, ytrain)
    acc.append(nn.score(xtest, ytest))

print(acc)

nn.score(xtest, ytest)

plot_confusion_matrix(nn, xtest, ytest,  normalize = 'pred')
sns.set(font_scale=0.75)
plt.show()

acc1 = []
j = 0
for i in alpha:
  acc1.append(acc[j])
  j+=4
plt.ylabel("Accuracy")
plt.xlabel("Learning rate")
plt.plot(alpha, acc1)

from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters=5)
kmeans.fit(xtrain, ytrain)

kmeans.score(xtest, ytest)

